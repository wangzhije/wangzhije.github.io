{"content":"<blockquote>\n<p>AI 技术虽然日新月异，但主要就是 Prompt（提示）、RAG、Agent。</p>\n</blockquote>\n<!-- > - AI 知识介绍 [https://guangzhengli.com/blog/zh/gpt-embeddings](https://guangzhengli.com/blog/zh/gpt-embeddings) -->\n<h2 id=\"prompt\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#prompt\"><span>Prompt</span></a></h2>\n<blockquote>\n<p>Prompt 指的是提供给模型的文本和指令，</p>\n<p>可以用来引导模型生成自然语言输出（Completion），</p>\n<p>可以给模型提供上下文信息，对模型的输出结果至关重要。</p>\n</blockquote>\n<p>AI 应用开发</p>\n<p>先是从 ChatGPT 开始</p>\n<p>然后是</p>\n<p>基于 AI 的翻译类的应用</p>\n<ul>\n<li><a href=\"https://github.com/openai-translator/openai-translator\" target=\"_blank\" rel=\"noopener noreferrer\">openai-translator</a></li>\n<li><a href=\"https://immersivetranslate.com/\" target=\"_blank\" rel=\"noopener noreferrer\">immersivetranslate</a>，</li>\n</ul>\n<p>写作类的应用</p>\n<ul>\n<li><a href=\"https://www.notion.so/product/ai\" target=\"_blank\" rel=\"noopener noreferrer\">Notion AI</a>，</li>\n</ul>\n<p>编程辅助类的应用</p>\n<ul>\n<li><a href=\"https://github.com/features/copilot\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub Copilot</a></li>\n<li><a href=\"https://docs.github.com/en/copilot/github-copilot-chat/using-github-copilot-chat?tool=vscode\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub Copilot Chat</a>，</li>\n</ul>\n<p>主要基于 GPT 的 Prompt（提示）实现。</p>\n<h3 id=\"gpt-模型\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#gpt-模型\"><span>GPT 模型</span></a></h3>\n<p>GPT（Generative Pre-trained Transformer）是一个推理模型，它主要基于预训练和微调两个阶段。</p>\n<p>预训练</p>\n<ul>\n<li>使用一个大规模的语料库进行基础训练，例如使用维基百科、新闻文章、小说等来进行训练</li>\n<li>当训练完成后，输入一句话给它，它会基于这句话给出一个概率上的预测，预测后续应该拼接上什么单词，这个拼接的单词是基于它在预训练阶段学习到的知识来进行概率选定的，通过一次次循环的单词预测，最终可以拼接出一段话来。这也是它被称为生成式 AI 的原因</li>\n<li>也就是 Prompt，是生成式 AI 概率生成的基础</li>\n</ul>\n<p>微调</p>\n<ul>\n<li>将 GPT 模型加载到特定的任务上，并使用该任务的数据集对模型进行训练</li>\n<li>模型就可以根据任务的要求进行微调，以便更好地理解 Prompt 并生成与任务相关的文本</li>\n<li>通过微调，GPT 可以适应不同的任务，如文本分类、情感分析、问答系统等</li>\n<li>成本昂贵，最终效果并不稳定</li>\n</ul>\n<h3 id=\"prompt-学习资料\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#prompt-学习资料\"><span>Prompt 学习资料</span></a></h3>\n<ul>\n<li>吴恩达 <a href=\"https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/\" target=\"_blank\" rel=\"noopener noreferrer\">ChatGPT Prompt 工程</a>，快速了解 Prompt 的使用方式</li>\n<li><a href=\"https://www.promptingguide.ai/\" target=\"_blank\" rel=\"noopener noreferrer\"> Prompt Engineering Guide</a>,包含了大量的 Prompt 基础知识和未来的发展方向</li>\n<li><a href=\"https://platform.openai.com/docs/guides/gpt-best-practices\" target=\"_blank\" rel=\"noopener noreferrer\">GPT 最佳实践</a>,OpenAI 官方文档实践指南，包含了大量的 Prompt 示例和使用技巧</li>\n</ul>\n<h2 id=\"rag\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#rag\"><span>RAG</span></a></h2>\n<blockquote>\n<p>RAG，Retrieval-augmented Generation，检索增强生成。</p>\n</blockquote>\n<p>Prompt 问题：</p>\n<ul>\n<li>Prompt 应用开发，是基于已有的大模型的训练数据，也就是时效性问题</li>\n<li>如果是基于最新的数据，没有基于这些数据进行训练，也就无法解决该类问题</li>\n<li>GPT Prompt 有大小限制，gpt-3.5-turbo 模型它的限制是 4K tokens(～ 3000 字)，这意味着使用者最多只能输入 3000 字给 GPT 来理解和推理答案</li>\n</ul>\n<p>RAG 应用：</p>\n<ul>\n<li>解决某些场景下 GPT 无法回答的问题，这是他最大的优点。</li>\n<li>无需训练，无需微调，只需要将文本转化为向量再通过检索就能实现，以低成本的方式就能让某些业务场景变成可能。</li>\n</ul>\n<h3 id=\"rag-应用核心思想\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#rag-应用核心思想\"><span>RAG 应用核心思想</span></a></h3>\n<p>通过向量检索的方式检索与问题最相关的文本段，从而绕过 GPT tokens 的限制。</p>\n<ul>\n<li>拆分：将参考文本拆分成多个部分</li>\n<li>将问题转化为向量：分别进行 RAG 转化为向量存储到向量数据库中</li>\n<li>通过向量数据库进行检索，最后再将检索到的向量转化为文本输出</li>\n</ul>\n<p>缺点： 文本拆分、查询范围、检索的质量，将在很大的程度上影响最终的结果</p>\n<h2 id=\"gpt-agents\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#gpt-agents\"><span>GPT Agents</span></a></h2>\n","env":{"base":"/blog/","filePath":"/Users/wangzhijie/Desktop/myspace/wangzhije.github.io/docs/notes/9.AI/1.介绍.md","filePathRelative":"notes/9.AI/1.介绍.md","frontmatter":{"title":"GPT","createTime":"2025/08/21 12:49:01","permalink":"/ai/gpt/"},"sfcBlocks":{"template":{"type":"template","content":"<template><blockquote>\n<p>AI 技术虽然日新月异，但主要就是 Prompt（提示）、RAG、Agent。</p>\n</blockquote>\n<!-- > - AI 知识介绍 [https://guangzhengli.com/blog/zh/gpt-embeddings](https://guangzhengli.com/blog/zh/gpt-embeddings) -->\n<h2 id=\"prompt\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#prompt\"><span>Prompt</span></a></h2>\n<blockquote>\n<p>Prompt 指的是提供给模型的文本和指令，</p>\n<p>可以用来引导模型生成自然语言输出（Completion），</p>\n<p>可以给模型提供上下文信息，对模型的输出结果至关重要。</p>\n</blockquote>\n<p>AI 应用开发</p>\n<p>先是从 ChatGPT 开始</p>\n<p>然后是</p>\n<p>基于 AI 的翻译类的应用</p>\n<ul>\n<li><a href=\"https://github.com/openai-translator/openai-translator\" target=\"_blank\" rel=\"noopener noreferrer\">openai-translator</a></li>\n<li><a href=\"https://immersivetranslate.com/\" target=\"_blank\" rel=\"noopener noreferrer\">immersivetranslate</a>，</li>\n</ul>\n<p>写作类的应用</p>\n<ul>\n<li><a href=\"https://www.notion.so/product/ai\" target=\"_blank\" rel=\"noopener noreferrer\">Notion AI</a>，</li>\n</ul>\n<p>编程辅助类的应用</p>\n<ul>\n<li><a href=\"https://github.com/features/copilot\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub Copilot</a></li>\n<li><a href=\"https://docs.github.com/en/copilot/github-copilot-chat/using-github-copilot-chat?tool=vscode\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub Copilot Chat</a>，</li>\n</ul>\n<p>主要基于 GPT 的 Prompt（提示）实现。</p>\n<h3 id=\"gpt-模型\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#gpt-模型\"><span>GPT 模型</span></a></h3>\n<p>GPT（Generative Pre-trained Transformer）是一个推理模型，它主要基于预训练和微调两个阶段。</p>\n<p>预训练</p>\n<ul>\n<li>使用一个大规模的语料库进行基础训练，例如使用维基百科、新闻文章、小说等来进行训练</li>\n<li>当训练完成后，输入一句话给它，它会基于这句话给出一个概率上的预测，预测后续应该拼接上什么单词，这个拼接的单词是基于它在预训练阶段学习到的知识来进行概率选定的，通过一次次循环的单词预测，最终可以拼接出一段话来。这也是它被称为生成式 AI 的原因</li>\n<li>也就是 Prompt，是生成式 AI 概率生成的基础</li>\n</ul>\n<p>微调</p>\n<ul>\n<li>将 GPT 模型加载到特定的任务上，并使用该任务的数据集对模型进行训练</li>\n<li>模型就可以根据任务的要求进行微调，以便更好地理解 Prompt 并生成与任务相关的文本</li>\n<li>通过微调，GPT 可以适应不同的任务，如文本分类、情感分析、问答系统等</li>\n<li>成本昂贵，最终效果并不稳定</li>\n</ul>\n<h3 id=\"prompt-学习资料\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#prompt-学习资料\"><span>Prompt 学习资料</span></a></h3>\n<ul>\n<li>吴恩达 <a href=\"https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/\" target=\"_blank\" rel=\"noopener noreferrer\">ChatGPT Prompt 工程</a>，快速了解 Prompt 的使用方式</li>\n<li><a href=\"https://www.promptingguide.ai/\" target=\"_blank\" rel=\"noopener noreferrer\"> Prompt Engineering Guide</a>,包含了大量的 Prompt 基础知识和未来的发展方向</li>\n<li><a href=\"https://platform.openai.com/docs/guides/gpt-best-practices\" target=\"_blank\" rel=\"noopener noreferrer\">GPT 最佳实践</a>,OpenAI 官方文档实践指南，包含了大量的 Prompt 示例和使用技巧</li>\n</ul>\n<h2 id=\"rag\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#rag\"><span>RAG</span></a></h2>\n<blockquote>\n<p>RAG，Retrieval-augmented Generation，检索增强生成。</p>\n</blockquote>\n<p>Prompt 问题：</p>\n<ul>\n<li>Prompt 应用开发，是基于已有的大模型的训练数据，也就是时效性问题</li>\n<li>如果是基于最新的数据，没有基于这些数据进行训练，也就无法解决该类问题</li>\n<li>GPT Prompt 有大小限制，gpt-3.5-turbo 模型它的限制是 4K tokens(～ 3000 字)，这意味着使用者最多只能输入 3000 字给 GPT 来理解和推理答案</li>\n</ul>\n<p>RAG 应用：</p>\n<ul>\n<li>解决某些场景下 GPT 无法回答的问题，这是他最大的优点。</li>\n<li>无需训练，无需微调，只需要将文本转化为向量再通过检索就能实现，以低成本的方式就能让某些业务场景变成可能。</li>\n</ul>\n<h3 id=\"rag-应用核心思想\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#rag-应用核心思想\"><span>RAG 应用核心思想</span></a></h3>\n<p>通过向量检索的方式检索与问题最相关的文本段，从而绕过 GPT tokens 的限制。</p>\n<ul>\n<li>拆分：将参考文本拆分成多个部分</li>\n<li>将问题转化为向量：分别进行 RAG 转化为向量存储到向量数据库中</li>\n<li>通过向量数据库进行检索，最后再将检索到的向量转化为文本输出</li>\n</ul>\n<p>缺点： 文本拆分、查询范围、检索的质量，将在很大的程度上影响最终的结果</p>\n<h2 id=\"gpt-agents\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#gpt-agents\"><span>GPT Agents</span></a></h2>\n</template>","contentStripped":"<blockquote>\n<p>AI 技术虽然日新月异，但主要就是 Prompt（提示）、RAG、Agent。</p>\n</blockquote>\n<!-- > - AI 知识介绍 [https://guangzhengli.com/blog/zh/gpt-embeddings](https://guangzhengli.com/blog/zh/gpt-embeddings) -->\n<h2 id=\"prompt\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#prompt\"><span>Prompt</span></a></h2>\n<blockquote>\n<p>Prompt 指的是提供给模型的文本和指令，</p>\n<p>可以用来引导模型生成自然语言输出（Completion），</p>\n<p>可以给模型提供上下文信息，对模型的输出结果至关重要。</p>\n</blockquote>\n<p>AI 应用开发</p>\n<p>先是从 ChatGPT 开始</p>\n<p>然后是</p>\n<p>基于 AI 的翻译类的应用</p>\n<ul>\n<li><a href=\"https://github.com/openai-translator/openai-translator\" target=\"_blank\" rel=\"noopener noreferrer\">openai-translator</a></li>\n<li><a href=\"https://immersivetranslate.com/\" target=\"_blank\" rel=\"noopener noreferrer\">immersivetranslate</a>，</li>\n</ul>\n<p>写作类的应用</p>\n<ul>\n<li><a href=\"https://www.notion.so/product/ai\" target=\"_blank\" rel=\"noopener noreferrer\">Notion AI</a>，</li>\n</ul>\n<p>编程辅助类的应用</p>\n<ul>\n<li><a href=\"https://github.com/features/copilot\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub Copilot</a></li>\n<li><a href=\"https://docs.github.com/en/copilot/github-copilot-chat/using-github-copilot-chat?tool=vscode\" target=\"_blank\" rel=\"noopener noreferrer\">GitHub Copilot Chat</a>，</li>\n</ul>\n<p>主要基于 GPT 的 Prompt（提示）实现。</p>\n<h3 id=\"gpt-模型\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#gpt-模型\"><span>GPT 模型</span></a></h3>\n<p>GPT（Generative Pre-trained Transformer）是一个推理模型，它主要基于预训练和微调两个阶段。</p>\n<p>预训练</p>\n<ul>\n<li>使用一个大规模的语料库进行基础训练，例如使用维基百科、新闻文章、小说等来进行训练</li>\n<li>当训练完成后，输入一句话给它，它会基于这句话给出一个概率上的预测，预测后续应该拼接上什么单词，这个拼接的单词是基于它在预训练阶段学习到的知识来进行概率选定的，通过一次次循环的单词预测，最终可以拼接出一段话来。这也是它被称为生成式 AI 的原因</li>\n<li>也就是 Prompt，是生成式 AI 概率生成的基础</li>\n</ul>\n<p>微调</p>\n<ul>\n<li>将 GPT 模型加载到特定的任务上，并使用该任务的数据集对模型进行训练</li>\n<li>模型就可以根据任务的要求进行微调，以便更好地理解 Prompt 并生成与任务相关的文本</li>\n<li>通过微调，GPT 可以适应不同的任务，如文本分类、情感分析、问答系统等</li>\n<li>成本昂贵，最终效果并不稳定</li>\n</ul>\n<h3 id=\"prompt-学习资料\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#prompt-学习资料\"><span>Prompt 学习资料</span></a></h3>\n<ul>\n<li>吴恩达 <a href=\"https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/\" target=\"_blank\" rel=\"noopener noreferrer\">ChatGPT Prompt 工程</a>，快速了解 Prompt 的使用方式</li>\n<li><a href=\"https://www.promptingguide.ai/\" target=\"_blank\" rel=\"noopener noreferrer\"> Prompt Engineering Guide</a>,包含了大量的 Prompt 基础知识和未来的发展方向</li>\n<li><a href=\"https://platform.openai.com/docs/guides/gpt-best-practices\" target=\"_blank\" rel=\"noopener noreferrer\">GPT 最佳实践</a>,OpenAI 官方文档实践指南，包含了大量的 Prompt 示例和使用技巧</li>\n</ul>\n<h2 id=\"rag\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#rag\"><span>RAG</span></a></h2>\n<blockquote>\n<p>RAG，Retrieval-augmented Generation，检索增强生成。</p>\n</blockquote>\n<p>Prompt 问题：</p>\n<ul>\n<li>Prompt 应用开发，是基于已有的大模型的训练数据，也就是时效性问题</li>\n<li>如果是基于最新的数据，没有基于这些数据进行训练，也就无法解决该类问题</li>\n<li>GPT Prompt 有大小限制，gpt-3.5-turbo 模型它的限制是 4K tokens(～ 3000 字)，这意味着使用者最多只能输入 3000 字给 GPT 来理解和推理答案</li>\n</ul>\n<p>RAG 应用：</p>\n<ul>\n<li>解决某些场景下 GPT 无法回答的问题，这是他最大的优点。</li>\n<li>无需训练，无需微调，只需要将文本转化为向量再通过检索就能实现，以低成本的方式就能让某些业务场景变成可能。</li>\n</ul>\n<h3 id=\"rag-应用核心思想\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#rag-应用核心思想\"><span>RAG 应用核心思想</span></a></h3>\n<p>通过向量检索的方式检索与问题最相关的文本段，从而绕过 GPT tokens 的限制。</p>\n<ul>\n<li>拆分：将参考文本拆分成多个部分</li>\n<li>将问题转化为向量：分别进行 RAG 转化为向量存储到向量数据库中</li>\n<li>通过向量数据库进行检索，最后再将检索到的向量转化为文本输出</li>\n</ul>\n<p>缺点： 文本拆分、查询范围、检索的质量，将在很大的程度上影响最终的结果</p>\n<h2 id=\"gpt-agents\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#gpt-agents\"><span>GPT Agents</span></a></h2>\n","tagOpen":"<template>","tagClose":"</template>"},"script":null,"scriptSetup":null,"scripts":[],"styles":[],"customBlocks":[]},"content":"> AI 技术虽然日新月异，但主要就是 Prompt（提示）、RAG、Agent。\n\n<!-- > - AI 知识介绍 [https://guangzhengli.com/blog/zh/gpt-embeddings](https://guangzhengli.com/blog/zh/gpt-embeddings) -->\n\n## Prompt\n\n> Prompt 指的是提供给模型的文本和指令，\n>\n> 可以用来引导模型生成自然语言输出（Completion），\n>\n> 可以给模型提供上下文信息，对模型的输出结果至关重要。\n\nAI 应用开发\n\n先是从 ChatGPT 开始\n\n然后是\n\n基于 AI 的翻译类的应用\n\n- [openai-translator](https://github.com/openai-translator/openai-translator)\n- [immersivetranslate](https://immersivetranslate.com/)，\n\n写作类的应用\n\n- [Notion AI](https://www.notion.so/product/ai)，\n\n编程辅助类的应用\n\n- [GitHub Copilot](https://github.com/features/copilot)\n- [GitHub Copilot Chat](https://docs.github.com/en/copilot/github-copilot-chat/using-github-copilot-chat?tool=vscode)，\n\n主要基于 GPT 的 Prompt（提示）实现。\n\n### GPT 模型\n\nGPT（Generative Pre-trained Transformer）是一个推理模型，它主要基于预训练和微调两个阶段。\n\n预训练\n\n- 使用一个大规模的语料库进行基础训练，例如使用维基百科、新闻文章、小说等来进行训练\n- 当训练完成后，输入一句话给它，它会基于这句话给出一个概率上的预测，预测后续应该拼接上什么单词，这个拼接的单词是基于它在预训练阶段学习到的知识来进行概率选定的，通过一次次循环的单词预测，最终可以拼接出一段话来。这也是它被称为生成式 AI 的原因\n- 也就是 Prompt，是生成式 AI 概率生成的基础\n\n微调\n\n- 将 GPT 模型加载到特定的任务上，并使用该任务的数据集对模型进行训练\n- 模型就可以根据任务的要求进行微调，以便更好地理解 Prompt 并生成与任务相关的文本\n- 通过微调，GPT 可以适应不同的任务，如文本分类、情感分析、问答系统等\n- 成本昂贵，最终效果并不稳定\n\n### Prompt 学习资料\n\n- 吴恩达 [ChatGPT Prompt 工程](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)，快速了解 Prompt 的使用方式\n- [ Prompt Engineering Guide](https://www.promptingguide.ai/),包含了大量的 Prompt 基础知识和未来的发展方向\n- [GPT 最佳实践](https://platform.openai.com/docs/guides/gpt-best-practices),OpenAI 官方文档实践指南，包含了大量的 Prompt 示例和使用技巧\n\n## RAG\n\n> RAG，Retrieval-augmented Generation，检索增强生成。\n\nPrompt 问题：\n\n- Prompt 应用开发，是基于已有的大模型的训练数据，也就是时效性问题\n- 如果是基于最新的数据，没有基于这些数据进行训练，也就无法解决该类问题\n- GPT Prompt 有大小限制，gpt-3.5-turbo 模型它的限制是 4K tokens(～ 3000 字)，这意味着使用者最多只能输入 3000 字给 GPT 来理解和推理答案\n\nRAG 应用：\n\n- 解决某些场景下 GPT 无法回答的问题，这是他最大的优点。\n- 无需训练，无需微调，只需要将文本转化为向量再通过检索就能实现，以低成本的方式就能让某些业务场景变成可能。\n\n### RAG 应用核心思想\n\n通过向量检索的方式检索与问题最相关的文本段，从而绕过 GPT tokens 的限制。\n\n- 拆分：将参考文本拆分成多个部分\n- 将问题转化为向量：分别进行 RAG 转化为向量存储到向量数据库中\n- 通过向量数据库进行检索，最后再将检索到的向量转化为文本输出\n\n缺点： 文本拆分、查询范围、检索的质量，将在很大的程度上影响最终的结果\n\n## GPT Agents","excerpt":"","includedFiles":[],"tasklistId":0,"title":"","headers":[{"level":2,"title":"Prompt","slug":"prompt","link":"#prompt","children":[{"level":3,"title":"GPT 模型","slug":"gpt-模型","link":"#gpt-模型","children":[]},{"level":3,"title":"Prompt 学习资料","slug":"prompt-学习资料","link":"#prompt-学习资料","children":[]}]},{"level":2,"title":"RAG","slug":"rag","link":"#rag","children":[{"level":3,"title":"RAG 应用核心思想","slug":"rag-应用核心思想","link":"#rag-应用核心思想","children":[]}]},{"level":2,"title":"GPT Agents","slug":"gpt-agents","link":"#gpt-agents","children":[]}]}}
